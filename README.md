# Claude Cortex

> A secure, multi-agent reasoning engine powered by Anthropic's Claude API that helps users think more deeply, from more angles — in seconds.

[![Next.js](https://img.shields.io/badge/Next.js-13+-black?style=flat-square&logo=next.js)](https://nextjs.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-green?style=flat-square&logo=fastapi)](https://fastapi.tiangolo.com/)
[![Claude](https://img.shields.io/badge/Claude-3.5-blue?style=flat-square)](https://www.anthropic.com/)
[![AWS Bedrock](https://img.shields.io/badge/AWS-Bedrock-orange?style=flat-square&logo=amazon-aws)](https://aws.amazon.com/bedrock/)

# [Demo]()

## The Problem

Today's LLMs are impressive at giving smart answers. But when the stakes are high, one answer isn't enough. Whether you're navigating a complex business strategy, a public policy dilemma, or an ethical gray area, you don't want just a chatbot. You want diverse expert reasoning, risk analysis, ethical reflection, and alternative thinking — fast, secure, and structured.

Right now, people simulate this by prompting Claude multiple times manually. It's slow, subjective, and inconsistent.

**Claude Cortex solves this.** It's a secure, multi-agent reasoning engine that helps users think more deeply, from more angles — in seconds.

## How It Works

### 1. Scenario Input
Users input a high-stakes scenario:
> *"We need to reduce operational costs by 20%. What's the best course of action?"*

### 2. Multi-Agent Analysis
Claude Cortex launches multiple task-based agents in parallel, each responsible for analyzing the problem from a different operational angle. These agents are dynamically generated by a master planning agent based on the nature of the scenario.

**Example agents for cost reduction scenario:**
- **Spend Analysis Agent** – Breaks down current expenditures, identifies major cost centers, and flags inefficient spending
- **Optimization Agent** – Proposes restructuring strategies, automation opportunities, and process improvements
- **Forecasting Agent** – Models the impact of different cost-cutting strategies on long-term performance
- **Workforce Impact Agent** – Evaluates implications on staffing, morale, and organizational capability

### 3. Parallel Execution
Each agent executes a task-specific prompt, designed to produce structured, actionable output. These tasks run concurrently using FastAPI's asynchronous threading model, enabling high-throughput reasoning without blocking execution.

### 4. Synthesis
A final Claude moderator agent synthesizes outputs from all agents — weighing tradeoffs, identifying synergies and risks, and producing a well-reasoned recommendation tailored to the original goal.

### 5. Secure Mode (Optional)
For security-critical use cases, users can enable **Secure Mode**, which routes all Claude calls through AWS Bedrock. This enables Claude Cortex to operate in sensitive environments such as enterprise infrastructure, healthcare systems, or regulated industries where compliance and data privacy are essential.

## Tech Stack

### Frontend
- **Next.js + TailwindCSS** - Clean, responsive UI for scenario input, multi-agent panels, and synthesis display

### Backend
- **FastAPI** - Lightweight, high-performance Python backend to orchestrate multi-agent flows and expose secure REST endpoints

### Multi-Agent Orchestration
- **LangGraph (built on LangChain)** - Manages agent state, role-driven prompts, and structured reasoning paths. Each agent functions as a modular, task-specific node in a directed graph, enabling scalable and flexible inference flows.

### LLM Integration
- **Claude via Anthropic API** – Primary inference engine for agent and synthesis nodes
- **Claude via AWS Bedrock** – Optional secure mode for enterprise-grade, compliant deployment
- **Parallel Inference** – Agents execute concurrently for low-latency multi-perspective reasoning

### Browser-Level Agentic Actions
- **browser-use** - Certain Claude agents can interact with live websites, enabling dynamic workflows such as reading external data, validating assumptions, or grounding recommendations in real-time content.

### Deployment
- **Frontend** - Hosted via Vercel
- **Backend** - Deployed via Railway
- **Secure Claude inference (Bedrock)** - Isolated via env-aware routing

## Why It Matters

Claude Cortex is more than an LLM chat interface, it's a **multi-agent reasoning architecture**. By transforming one scenario into several parallel expert analyses, and then synthesizing those into a final answer, it enables Claude to function like an intelligent decision panel — not a single voice.

This architecture pushes the boundaries of LLM orchestration, exploring what happens when we move from sequential prompting to structured, parallel reasoning and secure deployment. The system is natively built around Claude's strengths: long-context comprehension, chain-of-thought analysis, and role-driven reflection.

## Getting Started

### Prerequisites
- Node.js 18+ 
- Python 3.8+
- Anthropic API key
- (Optional) AWS Bedrock access for secure mode

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/claude-cortex.git
   cd claude-cortex
   ```

2. **Install frontend dependencies**
   ```bash
   cd frontend
   npm install
   ```

3. **Install backend dependencies**
   ```bash
   cd ../backend
   pip install -r requirements.txt
   ```

4. **Set up environment variables**
   ```bash
   # Copy example environment file
   cp .env.example .env
   
   # Add your API keys
   ANTHROPIC_API_KEY=your_api_key_here
   AWS_ACCESS_KEY_ID=your_aws_key_here  # For secure mode
   AWS_SECRET_ACCESS_KEY=your_aws_secret_here
   ```

5. **Run the application**
   ```bash
   # Start backend
   cd backend
   uvicorn main:app --reload
   
   # Start frontend (in new terminal)
   cd frontend
   npm run dev
   ```

## Usage

1. **Open the application** at `http://localhost:3000`
2. **Enter your scenario** in the input field
3. **Choose your mode**:
   - Standard mode for general use
   - Secure mode for sensitive/enterprise scenarios
4. **Watch the multi-agent analysis** unfold in real-time
5. **Review the synthesized recommendation**

## Architecture

```
┌─────────────────┐    ┌──────────────────┐    ┌─────────────────┐
│   Frontend      │    │    FastAPI        │    │   Claude API    │
│   (Next.js)     │◄──►│   Backend         │◄──►│   / Bedrock     │
└─────────────────┘    └──────────────────┘    └─────────────────┘
                              │
                              ▼
                    ┌──────────────────┐
                    │   LangGraph      │
                    │   Orchestration  │
                    └──────────────────┘
                              │
                              ▼
                    ┌──────────────────┐
                    │  Multi-Agent     │
                    │  Parallel        │
                    │  Execution       │
                    └──────────────────┘
```

## Contributing

We welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Built With

- [Amazon Web Services](https://aws.amazon.com/) - Bedrock integration
- [Claude](https://www.anthropic.com/) - AI reasoning engine
- [FastAPI](https://fastapi.tiangolo.com/) - Backend framework
- [LangChain](https://langchain.com/) - LLM orchestration
- [Next.js](https://nextjs.org/) - Frontend framework
- [Python](https://python.org/) - Backend language
- [TailwindCSS](https://tailwindcss.com/) - Styling framework

---

**Claude Cortex demonstrates a new paradigm: one where AI is not just reactive, but structured, secure, and pluralistic in its thinking. As LLMs are increasingly used for real-world decision-making, systems like this show how we can scale thoughtful, diverse reasoning — safely and reliably.**